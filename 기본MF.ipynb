{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=LJX5hdw-zUI&t=39s\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('ml-latest-small/links.csv'),\n",
       " PosixPath('ml-latest-small/README.txt'),\n",
       " PosixPath('ml-latest-small/movies.csv'),\n",
       " PosixPath('ml-latest-small/tags.csv'),\n",
       " PosixPath('ml-latest-small/ratings.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path(\"ml-latest-small\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating,timestamp\n",
      "1,1,4.0,964982703\n",
      "1,3,4.0,964981247\n",
      "1,6,4.0,964982224\n",
      "1,47,5.0,964983815\n",
      "1,50,5.0,964982931\n",
      "1,70,3.0,964982400\n",
      "1,101,5.0,964980868\n",
      "1,110,4.0,964982176\n",
      "1,151,5.0,964984041\n"
     ]
    }
   ],
   "source": [
    "! head ml-latest-small/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH/\"ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1458635171.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 인코딩 데이터\n",
    "# we encode the data to have contiguous ids for users and movies. you can think about this as a categorical encoding of out two categorical variables userid and movieid.\n",
    "## 우리는 사용자와 영화에 대해 연속적인 ID를 갖도록 데이터를 인코딩합니다. 이것을 두 개의 범주형 변수 userid와 movieid의 범주형 인코딩으로 생각할 수 있습니다.\n",
    "time_80 = np.quantile(data.timestamp.values,0.8)\n",
    "\n",
    "time_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data[\"timestamp\"] < time_80].copy()\n",
    "val = data[data[\"timestamp\"] >= time_80].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80668 20168\n"
     ]
    }
   ],
   "source": [
    "print(len(train),len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 유저아이디를 유니크, 정렬해줌\n",
    "train_user_ids = np.sort(np.unique(train.userId.values))\n",
    "# train_user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 유니크 아이디 숫자\n",
    "num_users = len(train_user_ids)\n",
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid2idx = {o:i for i,o in enumerate(train_user_ids)}\n",
    "# userid2idx\n",
    "# 왼쪽이 실데이터의 유저아이디, 오른쪽이 라벨번호(유저)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99529</th>\n",
       "      <td>521</td>\n",
       "      <td>892</td>\n",
       "      <td>3.0</td>\n",
       "      <td>847221080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99530</th>\n",
       "      <td>521</td>\n",
       "      <td>1056</td>\n",
       "      <td>3.0</td>\n",
       "      <td>847221080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99531</th>\n",
       "      <td>521</td>\n",
       "      <td>1059</td>\n",
       "      <td>3.0</td>\n",
       "      <td>847221054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99532</th>\n",
       "      <td>521</td>\n",
       "      <td>1150</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847221054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99533</th>\n",
       "      <td>521</td>\n",
       "      <td>1161</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847221080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80668 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating  timestamp\n",
       "0           0        1     4.0  964982703\n",
       "1           0        3     4.0  964981247\n",
       "2           0        6     4.0  964982224\n",
       "3           0       47     5.0  964983815\n",
       "4           0       50     5.0  964982931\n",
       "...       ...      ...     ...        ...\n",
       "99529     521      892     3.0  847221080\n",
       "99530     521     1056     3.0  847221080\n",
       "99531     521     1059     3.0  847221054\n",
       "99532     521     1150     4.0  847221054\n",
       "99533     521     1161     4.0  847221080\n",
       "\n",
       "[80668 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터 정제\n",
    "train[\"userId\"] = train[\"userId\"].apply(lambda x:userid2idx[x])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1510571970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>14</td>\n",
       "      <td>260</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1510571946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>14</td>\n",
       "      <td>293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1510571962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>14</td>\n",
       "      <td>296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1510571877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>-1</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>-1</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>-1</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>-1</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>-1</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20168 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "1434        14        1     2.5  1510577970\n",
       "1436        14       47     3.5  1510571970\n",
       "1440        14      260     5.0  1510571946\n",
       "1441        14      293     3.0  1510571962\n",
       "1442        14      296     4.0  1510571877\n",
       "...        ...      ...     ...         ...\n",
       "100831      -1   166534     4.0  1493848402\n",
       "100832      -1   168248     5.0  1493850091\n",
       "100833      -1   168250     5.0  1494273047\n",
       "100834      -1   168252     5.0  1493846352\n",
       "100835      -1   170875     3.0  1493846415\n",
       "\n",
       "[20168 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터 정제\n",
    "## -1 유저는 트래이닝 하지 않음\n",
    "val[\"userId\"] = val[\"userId\"].apply(lambda x:userid2idx.get(x,-1))\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1510571970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>14</td>\n",
       "      <td>260</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1510571946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>14</td>\n",
       "      <td>293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1510571962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>14</td>\n",
       "      <td>296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1510571877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95960</th>\n",
       "      <td>513</td>\n",
       "      <td>170705</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1521397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95961</th>\n",
       "      <td>513</td>\n",
       "      <td>172591</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1521467819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95962</th>\n",
       "      <td>513</td>\n",
       "      <td>174055</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1521397739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95963</th>\n",
       "      <td>513</td>\n",
       "      <td>176371</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1521397623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95964</th>\n",
       "      <td>513</td>\n",
       "      <td>177765</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1521397621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1921 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "1434       14        1     2.5  1510577970\n",
       "1436       14       47     3.5  1510571970\n",
       "1440       14      260     5.0  1510571946\n",
       "1441       14      293     3.0  1510571962\n",
       "1442       14      296     4.0  1510571877\n",
       "...       ...      ...     ...         ...\n",
       "95960     513   170705     5.0  1521397596\n",
       "95961     513   172591     4.5  1521467819\n",
       "95962     513   174055     4.0  1521397739\n",
       "95963     513   176371     4.0  1521397623\n",
       "95964     513   177765     4.5  1521397621\n",
       "\n",
       "[1921 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = val[val[\"userId\"] >= 0].copy()\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     1,      2,      3, ..., 150548, 152711, 155168])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 임베딩 무비 아이디\n",
    "\n",
    "train_movie_ids = np.sort(np.unique(train.movieId.values))\n",
    "num_items = len(train_movie_ids)\n",
    "print(num_items)\n",
    "train_movie_ids\n",
    "## 실제 영화 종류는 7867개임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieid2idx = {o:i for i,o in enumerate(train_movie_ids)}\n",
    "train[\"movieId\"] = train[\"movieId\"].apply(lambda x: movieid2idx[x])\n",
    "val[\"movieId\"] = val[\"movieId\"].apply(lambda x: movieid2idx.get(x,-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1510571970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>14</td>\n",
       "      <td>224</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1510571946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>14</td>\n",
       "      <td>254</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1510571962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>14</td>\n",
       "      <td>257</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1510571877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95945</th>\n",
       "      <td>513</td>\n",
       "      <td>7352</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1521397830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95946</th>\n",
       "      <td>513</td>\n",
       "      <td>7507</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1521397833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95949</th>\n",
       "      <td>513</td>\n",
       "      <td>7619</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1521467672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95950</th>\n",
       "      <td>513</td>\n",
       "      <td>7653</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1521398264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95954</th>\n",
       "      <td>513</td>\n",
       "      <td>7803</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1521397599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1311 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "1434       14        0     2.5  1510577970\n",
       "1436       14       43     3.5  1510571970\n",
       "1440       14      224     5.0  1510571946\n",
       "1441       14      254     3.0  1510571962\n",
       "1442       14      257     4.0  1510571877\n",
       "...       ...      ...     ...         ...\n",
       "95945     513     7352     4.0  1521397830\n",
       "95946     513     7507     4.5  1521397833\n",
       "95949     513     7619     4.0  1521467672\n",
       "95950     513     7653     4.5  1521398264\n",
       "95954     513     7803     5.0  1521397599\n",
       "\n",
       "[1311 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = val[val[\"movieId\"] >= 0 ].copy()\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 임베딩 레이어\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 웨이트 Parameter containing:\n",
      "tensor([[-0.5456,  0.3833, -0.8424],\n",
      "        [ 0.6062, -0.1263,  0.7278],\n",
      "        [ 0.6806,  0.4229,  1.0881],\n",
      "        [-1.5685,  0.4669, -1.7190],\n",
      "        [ 0.5448, -0.5164,  0.3161],\n",
      "        [-1.7242,  0.3768,  0.5971],\n",
      "        [-1.1567,  0.1724, -0.2945],\n",
      "        [-0.5785,  1.3830, -1.1507],\n",
      "        [-1.7807, -0.1004, -1.8281],\n",
      "        [-0.8879,  0.6091, -2.3706]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "embed = nn.Embedding(10,3)\n",
    "print(\"임베딩 웨이트\",embed.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self,num_users,num_items,emb_size=512):\n",
    "        super(MF,self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items,emb_size)\n",
    "        \n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "    \n",
    "    def forward(self,u,v):\n",
    "        u = self.user_emb(u)\n",
    "        v = self.item_emb(v)\n",
    "        \n",
    "        return (u*v).sum(1)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating\n",
      "0       0        0       4\n",
      "1       0        1       5\n",
      "2       1        2       3\n",
      "3       1        1       1\n",
      "4       3        3       3\n",
      "5       4        0       4\n"
     ]
    }
   ],
   "source": [
    "# MF 모델 디버깅\n",
    "df = pd.DataFrame({\"userId\":[0,0,1,1,3,4],\"movieId\":[0,1,2,1,3,0],\"rating\":[4,5,3,1,3,4]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 5\n",
    "num_item = 4\n",
    "emb_size = 3\n",
    "\n",
    "user_emb = nn.Embedding(num_users,emb_size)\n",
    "item_emb = nn.Embedding(num_items,emb_size)\n",
    "users = torch.LongTensor(df.userId.values)\n",
    "items = torch.LongTensor(df.movieId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = user_emb(users)\n",
    "V = item_emb(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3]) torch.Size([6, 3])\n",
      "tensor([[-0.0454,  1.3591,  0.4848],\n",
      "        [-0.0454,  1.3591,  0.4848],\n",
      "        [ 1.0756,  0.6630,  1.9769],\n",
      "        [ 1.0756,  0.6630,  1.9769],\n",
      "        [-0.3693,  1.4941, -0.7260],\n",
      "        [ 0.5897, -2.0387, -1.2035]], grad_fn=<EmbeddingBackward>) \n",
      " tensor([[-1.5235, -0.8728, -0.5908],\n",
      "        [-1.0782,  0.1864, -0.6271],\n",
      "        [-0.6850,  0.2223, -2.0722],\n",
      "        [-1.0782,  0.1864, -0.6271],\n",
      "        [-0.2778,  0.8583, -1.1754],\n",
      "        [-1.5235, -0.8728, -0.5908]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(U.shape,V.shape)\n",
    "print(U,\"\\n\",V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0692, -1.1862, -0.2865],\n",
      "        [ 0.0489,  0.2533, -0.3041],\n",
      "        [-0.7368,  0.1474, -4.0965],\n",
      "        [-1.1598,  0.1236, -1.2397],\n",
      "        [ 0.1026,  1.2824,  0.8533],\n",
      "        [-0.8984,  1.7793,  0.7111]], grad_fn=<MulBackward0>) \n",
      " torch.Size([6, 3])\n",
      "tensor([-1.4035e+00, -1.8407e-03, -4.6859e+00, -2.2759e+00,  2.2383e+00,\n",
      "         1.5920e+00], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "## 단순 행렬 요소끼리의 곱 element wise multiplication\n",
    "print(U*V,\"\\n\",(U*V).shape)\n",
    "print((U*V).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522 7867\n"
     ]
    }
   ],
   "source": [
    "## 학습\n",
    "num_users=  len(train.userId.unique())\n",
    "num_items = len(train.movieId.unique())\n",
    "print(num_users,num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (user_emb): Embedding(522, 512)\n",
       "  (item_emb): Embedding(7867, 512)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = MF(num_users,num_items,emb_size=512)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch , train loss : 11.234 \t val_loss : 9.562 \t 0.0\n",
      "1 epoch , train loss : 9.370 \t val_loss : 7.374 \t 0.0\n",
      "2 epoch , train loss : 7.180 \t val_loss : 5.105 \t 0.0\n",
      "3 epoch , train loss : 4.908 \t val_loss : 3.068 \t 0.0\n",
      "4 epoch , train loss : 2.868 \t val_loss : 1.641 \t 0.0\n",
      "5 epoch , train loss : 1.439 \t val_loss : 1.158 \t 0.0\n",
      "6 epoch , train loss : 0.961 \t val_loss : 1.636 \t 0.0\n",
      "7 epoch , train loss : 1.430 \t val_loss : 2.568 \t 0.0\n",
      "8 epoch , train loss : 2.240 \t val_loss : 3.221 \t 0.0\n",
      "9 epoch , train loss : 2.655 \t val_loss : 3.242 \t 0.0\n",
      "10 epoch , train loss : 2.464 \t val_loss : 2.762 \t 0.0\n",
      "11 epoch , train loss : 1.907 \t val_loss : 2.107 \t 0.0\n",
      "12 epoch , train loss : 1.311 \t val_loss : 1.546 \t 0.0\n",
      "13 epoch , train loss : 0.901 \t val_loss : 1.208 \t 0.0\n",
      "14 epoch , train loss : 0.752 \t val_loss : 1.096 \t 0.0\n",
      "15 epoch , train loss : 0.819 \t val_loss : 1.138 \t 0.0\n",
      "16 epoch , train loss : 1.001 \t val_loss : 1.244 \t 0.0\n",
      "17 epoch , train loss : 1.197 \t val_loss : 1.338 \t 0.0\n",
      "18 epoch , train loss : 1.332 \t val_loss : 1.375 \t 0.0\n",
      "19 epoch , train loss : 1.370 \t val_loss : 1.341 \t 0.0\n",
      "20 epoch , train loss : 1.307 \t val_loss : 1.247 \t 0.0\n",
      "21 epoch , train loss : 1.166 \t val_loss : 1.124 \t 0.0\n",
      "22 epoch , train loss : 0.985 \t val_loss : 1.008 \t 0.0\n",
      "23 epoch , train loss : 0.811 \t val_loss : 0.937 \t 0.0\n",
      "24 epoch , train loss : 0.687 \t val_loss : 0.933 \t 0.0\n",
      "25 epoch , train loss : 0.640 \t val_loss : 0.994 \t 0.0\n",
      "26 epoch , train loss : 0.670 \t val_loss : 1.093 \t 0.0\n",
      "27 epoch , train loss : 0.748 \t val_loss : 1.186 \t 0.0\n",
      "28 epoch , train loss : 0.827 \t val_loss : 1.234 \t 0.0\n",
      "29 epoch , train loss : 0.866 \t val_loss : 1.218 \t 0.0\n",
      "30 epoch , train loss : 0.847 \t val_loss : 1.148 \t 0.0\n",
      "31 epoch , train loss : 0.782 \t val_loss : 1.052 \t 0.0\n",
      "32 epoch , train loss : 0.702 \t val_loss : 0.960 \t 0.0\n",
      "33 epoch , train loss : 0.639 \t val_loss : 0.896 \t 0.0\n",
      "34 epoch , train loss : 0.608 \t val_loss : 0.865 \t 0.0\n",
      "35 epoch , train loss : 0.612 \t val_loss : 0.862 \t 0.0\n",
      "36 epoch , train loss : 0.638 \t val_loss : 0.874 \t 0.0\n",
      "37 epoch , train loss : 0.668 \t val_loss : 0.887 \t 0.0\n",
      "38 epoch , train loss : 0.687 \t val_loss : 0.893 \t 0.0\n",
      "39 epoch , train loss : 0.686 \t val_loss : 0.891 \t 0.0\n",
      "40 epoch , train loss : 0.667 \t val_loss : 0.884 \t 0.0\n",
      "41 epoch , train loss : 0.635 \t val_loss : 0.880 \t 0.0\n",
      "42 epoch , train loss : 0.604 \t val_loss : 0.885 \t 0.0\n",
      "43 epoch , train loss : 0.581 \t val_loss : 0.902 \t 0.0\n",
      "44 epoch , train loss : 0.573 \t val_loss : 0.927 \t 0.0\n",
      "45 epoch , train loss : 0.577 \t val_loss : 0.953 \t 0.0\n",
      "46 epoch , train loss : 0.588 \t val_loss : 0.972 \t 0.0\n",
      "47 epoch , train loss : 0.597 \t val_loss : 0.975 \t 0.0\n",
      "48 epoch , train loss : 0.596 \t val_loss : 0.963 \t 0.0\n",
      "49 epoch , train loss : 0.585 \t val_loss : 0.940 \t 0.0\n",
      "50 epoch , train loss : 0.568 \t val_loss : 0.912 \t 0.0\n",
      "51 epoch , train loss : 0.552 \t val_loss : 0.886 \t 0.0\n",
      "52 epoch , train loss : 0.541 \t val_loss : 0.867 \t 0.0\n",
      "53 epoch , train loss : 0.536 \t val_loss : 0.856 \t 0.0\n",
      "54 epoch , train loss : 0.536 \t val_loss : 0.850 \t 0.0\n",
      "55 epoch , train loss : 0.538 \t val_loss : 0.849 \t 0.0\n",
      "56 epoch , train loss : 0.536 \t val_loss : 0.849 \t 0.0\n",
      "57 epoch , train loss : 0.531 \t val_loss : 0.852 \t 0.0\n",
      "58 epoch , train loss : 0.522 \t val_loss : 0.857 \t 0.0\n",
      "59 epoch , train loss : 0.511 \t val_loss : 0.864 \t 0.0\n",
      "60 epoch , train loss : 0.501 \t val_loss : 0.875 \t 0.0\n",
      "61 epoch , train loss : 0.493 \t val_loss : 0.886 \t 0.0\n",
      "62 epoch , train loss : 0.488 \t val_loss : 0.897 \t 0.0\n",
      "63 epoch , train loss : 0.485 \t val_loss : 0.904 \t 0.0\n",
      "64 epoch , train loss : 0.481 \t val_loss : 0.906 \t 0.0\n",
      "65 epoch , train loss : 0.475 \t val_loss : 0.903 \t 0.0\n",
      "66 epoch , train loss : 0.468 \t val_loss : 0.897 \t 0.0\n",
      "67 epoch , train loss : 0.459 \t val_loss : 0.888 \t 0.0\n",
      "68 epoch , train loss : 0.450 \t val_loss : 0.880 \t 0.0\n",
      "69 epoch , train loss : 0.442 \t val_loss : 0.873 \t 0.0\n",
      "70 epoch , train loss : 0.436 \t val_loss : 0.867 \t 0.0\n",
      "71 epoch , train loss : 0.430 \t val_loss : 0.864 \t 0.0\n",
      "72 epoch , train loss : 0.424 \t val_loss : 0.862 \t 0.0\n",
      "73 epoch , train loss : 0.417 \t val_loss : 0.862 \t 0.0\n",
      "74 epoch , train loss : 0.410 \t val_loss : 0.864 \t 0.0\n",
      "75 epoch , train loss : 0.401 \t val_loss : 0.867 \t 0.0\n",
      "76 epoch , train loss : 0.393 \t val_loss : 0.871 \t 0.0\n",
      "77 epoch , train loss : 0.385 \t val_loss : 0.875 \t 0.0\n",
      "78 epoch , train loss : 0.378 \t val_loss : 0.879 \t 0.0\n",
      "79 epoch , train loss : 0.371 \t val_loss : 0.881 \t 0.0\n",
      "80 epoch , train loss : 0.364 \t val_loss : 0.881 \t 0.0\n",
      "81 epoch , train loss : 0.356 \t val_loss : 0.879 \t 0.0\n",
      "82 epoch , train loss : 0.349 \t val_loss : 0.877 \t 0.0\n",
      "83 epoch , train loss : 0.340 \t val_loss : 0.873 \t 0.0\n",
      "84 epoch , train loss : 0.332 \t val_loss : 0.870 \t 0.0\n",
      "85 epoch , train loss : 0.325 \t val_loss : 0.868 \t 0.0\n",
      "86 epoch , train loss : 0.317 \t val_loss : 0.866 \t 0.0\n",
      "87 epoch , train loss : 0.310 \t val_loss : 0.866 \t 0.0\n",
      "88 epoch , train loss : 0.302 \t val_loss : 0.866 \t 0.0\n",
      "89 epoch , train loss : 0.294 \t val_loss : 0.867 \t 0.0\n",
      "90 epoch , train loss : 0.287 \t val_loss : 0.869 \t 0.0\n",
      "91 epoch , train loss : 0.279 \t val_loss : 0.871 \t 0.0\n",
      "92 epoch , train loss : 0.271 \t val_loss : 0.873 \t 0.0\n",
      "93 epoch , train loss : 0.264 \t val_loss : 0.875 \t 0.0\n",
      "94 epoch , train loss : 0.256 \t val_loss : 0.875 \t 0.0\n",
      "95 epoch , train loss : 0.249 \t val_loss : 0.875 \t 0.0\n",
      "96 epoch , train loss : 0.242 \t val_loss : 0.874 \t 0.0\n",
      "97 epoch , train loss : 0.235 \t val_loss : 0.872 \t 0.0\n",
      "98 epoch , train loss : 0.228 \t val_loss : 0.870 \t 0.0\n",
      "99 epoch , train loss : 0.220 \t val_loss : 0.868 \t 0.0\n",
      "100 epoch , train loss : 0.214 \t val_loss : 0.867 \t 0.0\n",
      "101 epoch , train loss : 0.207 \t val_loss : 0.866 \t 0.0\n",
      "102 epoch , train loss : 0.200 \t val_loss : 0.866 \t 0.0\n",
      "103 epoch , train loss : 0.194 \t val_loss : 0.867 \t 0.0\n",
      "104 epoch , train loss : 0.188 \t val_loss : 0.868 \t 0.0\n",
      "105 epoch , train loss : 0.181 \t val_loss : 0.869 \t 0.0\n",
      "106 epoch , train loss : 0.175 \t val_loss : 0.870 \t 0.0\n",
      "107 epoch , train loss : 0.169 \t val_loss : 0.871 \t 0.0\n",
      "108 epoch , train loss : 0.163 \t val_loss : 0.872 \t 0.0\n",
      "109 epoch , train loss : 0.158 \t val_loss : 0.873 \t 0.0\n",
      "110 epoch , train loss : 0.152 \t val_loss : 0.873 \t 0.0\n",
      "111 epoch , train loss : 0.147 \t val_loss : 0.872 \t 0.0\n",
      "112 epoch , train loss : 0.142 \t val_loss : 0.871 \t 0.0\n",
      "113 epoch , train loss : 0.137 \t val_loss : 0.870 \t 0.0\n",
      "114 epoch , train loss : 0.132 \t val_loss : 0.869 \t 0.0\n",
      "115 epoch , train loss : 0.127 \t val_loss : 0.869 \t 0.0\n",
      "116 epoch , train loss : 0.123 \t val_loss : 0.869 \t 0.0\n",
      "117 epoch , train loss : 0.119 \t val_loss : 0.869 \t 0.0\n",
      "118 epoch , train loss : 0.114 \t val_loss : 0.869 \t 0.0\n",
      "119 epoch , train loss : 0.110 \t val_loss : 0.870 \t 0.0\n",
      "120 epoch , train loss : 0.106 \t val_loss : 0.871 \t 0.0\n",
      "121 epoch , train loss : 0.102 \t val_loss : 0.871 \t 0.0\n",
      "122 epoch , train loss : 0.099 \t val_loss : 0.872 \t 0.0\n",
      "123 epoch , train loss : 0.095 \t val_loss : 0.872 \t 0.0\n",
      "124 epoch , train loss : 0.092 \t val_loss : 0.873 \t 0.0\n",
      "125 epoch , train loss : 0.088 \t val_loss : 0.873 \t 0.0\n",
      "126 epoch , train loss : 0.085 \t val_loss : 0.872 \t 0.0\n",
      "127 epoch , train loss : 0.082 \t val_loss : 0.872 \t 0.0\n",
      "128 epoch , train loss : 0.079 \t val_loss : 0.872 \t 0.0\n",
      "129 epoch , train loss : 0.076 \t val_loss : 0.872 \t 0.0\n",
      "130 epoch , train loss : 0.073 \t val_loss : 0.872 \t 0.0\n",
      "131 epoch , train loss : 0.071 \t val_loss : 0.873 \t 0.0\n",
      "132 epoch , train loss : 0.068 \t val_loss : 0.873 \t 0.0\n",
      "133 epoch , train loss : 0.066 \t val_loss : 0.874 \t 0.0\n",
      "134 epoch , train loss : 0.063 \t val_loss : 0.874 \t 0.0\n",
      "135 epoch , train loss : 0.061 \t val_loss : 0.875 \t 0.0\n",
      "136 epoch , train loss : 0.059 \t val_loss : 0.875 \t 0.0\n",
      "137 epoch , train loss : 0.057 \t val_loss : 0.876 \t 0.0\n",
      "138 epoch , train loss : 0.054 \t val_loss : 0.876 \t 0.0\n",
      "139 epoch , train loss : 0.052 \t val_loss : 0.876 \t 0.0\n",
      "140 epoch , train loss : 0.051 \t val_loss : 0.876 \t 0.0\n",
      "141 epoch , train loss : 0.049 \t val_loss : 0.876 \t 0.0\n",
      "142 epoch , train loss : 0.047 \t val_loss : 0.877 \t 0.0\n",
      "143 epoch , train loss : 0.045 \t val_loss : 0.877 \t 0.0\n",
      "144 epoch , train loss : 0.044 \t val_loss : 0.877 \t 0.0\n",
      "145 epoch , train loss : 0.042 \t val_loss : 0.877 \t 0.0\n",
      "146 epoch , train loss : 0.041 \t val_loss : 0.878 \t 0.0\n",
      "147 epoch , train loss : 0.039 \t val_loss : 0.878 \t 0.0\n",
      "148 epoch , train loss : 0.038 \t val_loss : 0.879 \t 0.0\n",
      "149 epoch , train loss : 0.036 \t val_loss : 0.879 \t 0.0\n",
      "150 epoch , train loss : 0.035 \t val_loss : 0.879 \t 0.0\n",
      "151 epoch , train loss : 0.034 \t val_loss : 0.880 \t 0.0\n",
      "152 epoch , train loss : 0.033 \t val_loss : 0.880 \t 0.0\n",
      "153 epoch , train loss : 0.031 \t val_loss : 0.880 \t 0.0\n",
      "154 epoch , train loss : 0.030 \t val_loss : 0.880 \t 0.0\n",
      "155 epoch , train loss : 0.029 \t val_loss : 0.880 \t 0.0\n",
      "156 epoch , train loss : 0.028 \t val_loss : 0.881 \t 0.0\n",
      "157 epoch , train loss : 0.027 \t val_loss : 0.881 \t 0.0\n",
      "158 epoch , train loss : 0.026 \t val_loss : 0.881 \t 0.0\n",
      "159 epoch , train loss : 0.025 \t val_loss : 0.881 \t 0.0\n",
      "160 epoch , train loss : 0.025 \t val_loss : 0.882 \t 0.0\n",
      "161 epoch , train loss : 0.024 \t val_loss : 0.882 \t 0.0\n",
      "162 epoch , train loss : 0.023 \t val_loss : 0.882 \t 0.0\n",
      "163 epoch , train loss : 0.022 \t val_loss : 0.882 \t 0.0\n",
      "164 epoch , train loss : 0.021 \t val_loss : 0.883 \t 0.0\n",
      "165 epoch , train loss : 0.021 \t val_loss : 0.883 \t 0.0\n",
      "166 epoch , train loss : 0.020 \t val_loss : 0.883 \t 0.0\n",
      "167 epoch , train loss : 0.019 \t val_loss : 0.883 \t 0.0\n",
      "168 epoch , train loss : 0.019 \t val_loss : 0.883 \t 0.0\n",
      "169 epoch , train loss : 0.018 \t val_loss : 0.883 \t 0.0\n",
      "170 epoch , train loss : 0.017 \t val_loss : 0.883 \t 0.0\n",
      "171 epoch , train loss : 0.017 \t val_loss : 0.883 \t 0.0\n",
      "172 epoch , train loss : 0.016 \t val_loss : 0.884 \t 0.0\n",
      "173 epoch , train loss : 0.016 \t val_loss : 0.884 \t 0.0\n",
      "174 epoch , train loss : 0.015 \t val_loss : 0.884 \t 0.0\n",
      "175 epoch , train loss : 0.015 \t val_loss : 0.884 \t 0.0\n",
      "176 epoch , train loss : 0.014 \t val_loss : 0.884 \t 0.0\n",
      "177 epoch , train loss : 0.014 \t val_loss : 0.884 \t 0.0\n",
      "178 epoch , train loss : 0.013 \t val_loss : 0.884 \t 0.0\n",
      "179 epoch , train loss : 0.013 \t val_loss : 0.885 \t 0.0\n",
      "180 epoch , train loss : 0.012 \t val_loss : 0.885 \t 0.0\n",
      "181 epoch , train loss : 0.012 \t val_loss : 0.885 \t 0.0\n",
      "182 epoch , train loss : 0.012 \t val_loss : 0.885 \t 0.0\n",
      "183 epoch , train loss : 0.011 \t val_loss : 0.885 \t 0.0\n",
      "184 epoch , train loss : 0.011 \t val_loss : 0.885 \t 0.0\n",
      "185 epoch , train loss : 0.010 \t val_loss : 0.885 \t 0.0\n",
      "186 epoch , train loss : 0.010 \t val_loss : 0.885 \t 0.0\n",
      "187 epoch , train loss : 0.010 \t val_loss : 0.885 \t 0.0\n",
      "188 epoch , train loss : 0.010 \t val_loss : 0.885 \t 0.0\n",
      "189 epoch , train loss : 0.009 \t val_loss : 0.886 \t 0.0\n",
      "190 epoch , train loss : 0.009 \t val_loss : 0.886 \t 0.0\n",
      "191 epoch , train loss : 0.009 \t val_loss : 0.886 \t 0.0\n",
      "192 epoch , train loss : 0.008 \t val_loss : 0.886 \t 0.0\n",
      "193 epoch , train loss : 0.008 \t val_loss : 0.886 \t 0.0\n",
      "194 epoch , train loss : 0.008 \t val_loss : 0.886 \t 0.0\n",
      "195 epoch , train loss : 0.008 \t val_loss : 0.886 \t 0.0\n",
      "196 epoch , train loss : 0.007 \t val_loss : 0.886 \t 0.0\n",
      "197 epoch , train loss : 0.007 \t val_loss : 0.886 \t 0.0\n",
      "198 epoch , train loss : 0.007 \t val_loss : 0.886 \t 0.0\n",
      "199 epoch , train loss : 0.007 \t val_loss : 0.886 \t 0.0\n",
      "200 epoch , train loss : 0.006 \t val_loss : 0.886 \t 0.0\n",
      "201 epoch , train loss : 0.006 \t val_loss : 0.887 \t 0.0\n",
      "202 epoch , train loss : 0.006 \t val_loss : 0.887 \t 0.0\n",
      "203 epoch , train loss : 0.006 \t val_loss : 0.887 \t 0.0\n",
      "204 epoch , train loss : 0.006 \t val_loss : 0.887 \t 0.0\n",
      "205 epoch , train loss : 0.006 \t val_loss : 0.887 \t 0.0\n",
      "206 epoch , train loss : 0.005 \t val_loss : 0.887 \t 0.0\n",
      "207 epoch , train loss : 0.005 \t val_loss : 0.887 \t 0.0\n",
      "208 epoch , train loss : 0.005 \t val_loss : 0.887 \t 0.0\n",
      "209 epoch , train loss : 0.005 \t val_loss : 0.887 \t 0.0\n",
      "210 epoch , train loss : 0.005 \t val_loss : 0.887 \t 0.0\n",
      "211 epoch , train loss : 0.005 \t val_loss : 0.887 \t 0.0\n",
      "212 epoch , train loss : 0.004 \t val_loss : 0.887 \t 0.0\n",
      "213 epoch , train loss : 0.004 \t val_loss : 0.887 \t 0.0\n",
      "214 epoch , train loss : 0.004 \t val_loss : 0.887 \t 0.0\n",
      "215 epoch , train loss : 0.004 \t val_loss : 0.887 \t 0.0\n",
      "216 epoch , train loss : 0.004 \t val_loss : 0.887 \t 0.0\n",
      "217 epoch , train loss : 0.004 \t val_loss : 0.887 \t 0.0\n",
      "218 epoch , train loss : 0.004 \t val_loss : 0.888 \t 0.0\n",
      "219 epoch , train loss : 0.004 \t val_loss : 0.888 \t 0.0\n",
      "220 epoch , train loss : 0.004 \t val_loss : 0.888 \t 0.0\n",
      "221 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "222 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "223 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "224 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "225 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "226 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "227 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "228 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "229 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "230 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "231 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "232 epoch , train loss : 0.003 \t val_loss : 0.888 \t 0.0\n",
      "233 epoch , train loss : 0.002 \t val_loss : 0.888 \t 0.0\n",
      "234 epoch , train loss : 0.002 \t val_loss : 0.888 \t 0.0\n",
      "235 epoch , train loss : 0.002 \t val_loss : 0.888 \t 0.0\n",
      "236 epoch , train loss : 0.002 \t val_loss : 0.888 \t 0.0\n",
      "237 epoch , train loss : 0.002 \t val_loss : 0.888 \t 0.0\n",
      "238 epoch , train loss : 0.002 \t val_loss : 0.888 \t 0.0\n",
      "239 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "240 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "241 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "242 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "243 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "244 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "245 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "246 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "247 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "248 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "249 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "250 epoch , train loss : 0.002 \t val_loss : 0.889 \t 0.0\n",
      "251 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "252 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "253 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "254 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "255 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "256 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "257 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "258 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "259 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "260 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "261 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "262 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "263 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "264 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "265 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "266 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "267 epoch , train loss : 0.001 \t val_loss : 0.889 \t 0.0\n",
      "268 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "269 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "270 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "271 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "272 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "273 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "274 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "275 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "276 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "277 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "278 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "279 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "280 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "281 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "282 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "283 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "284 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "285 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "286 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "287 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "288 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "289 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "290 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "291 epoch , train loss : 0.001 \t val_loss : 0.890 \t 0.0\n",
      "292 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "293 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "294 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "295 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "296 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "297 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "298 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "299 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "300 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "301 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "302 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "303 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "304 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "305 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "306 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "307 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "308 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "309 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "310 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "311 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "312 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "313 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "314 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "315 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "316 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "317 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "318 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "319 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "320 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "321 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "322 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "323 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "324 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "325 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "326 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "327 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "328 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "329 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "330 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "331 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "332 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "333 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "334 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "335 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "336 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "337 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "338 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "339 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "340 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "341 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "342 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "343 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "344 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "345 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "346 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "347 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "348 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "349 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "350 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "351 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "352 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "353 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "354 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "355 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "356 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "357 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "358 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "359 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "360 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "361 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "362 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "363 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "364 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "365 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "366 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "367 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "368 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "369 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "370 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "371 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "372 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "373 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "374 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "375 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "376 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "377 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "378 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "379 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "380 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "381 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "382 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "383 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "384 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "385 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "386 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "387 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "388 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "389 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "390 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "391 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "392 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "393 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "394 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "395 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "396 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "397 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "398 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "399 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "400 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "401 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "402 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "403 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "404 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "405 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "406 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "407 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "408 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "409 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "410 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "411 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "412 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "413 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "414 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "415 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "416 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "417 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "418 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "419 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "420 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "421 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "422 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "423 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "424 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "425 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "426 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "427 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "428 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "429 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "430 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "431 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "432 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "433 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "434 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "435 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "436 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "437 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "438 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "439 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "440 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "441 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "442 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "443 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "444 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "445 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "446 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "447 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "448 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "449 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "450 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "451 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "452 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "453 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "454 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "455 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "456 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "457 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "458 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "459 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "460 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "461 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "462 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "463 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "464 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "465 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "466 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "467 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "468 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "469 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "470 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "471 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "472 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "473 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "474 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "475 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "476 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "477 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "478 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "479 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "480 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "481 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "482 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "483 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "484 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "485 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "486 epoch , train loss : 0.000 \t val_loss : 0.891 \t 0.0\n",
      "487 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "488 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "489 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "490 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "491 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "492 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "493 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "494 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "495 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "496 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "497 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "498 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "499 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "500 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "501 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "502 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "503 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "504 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "505 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "506 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "507 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "508 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "509 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "510 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "511 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "512 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "513 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "514 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "515 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "516 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "517 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "518 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "519 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "520 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "521 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "522 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "523 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "524 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "525 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "526 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "527 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "528 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "529 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "530 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "531 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "532 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "533 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "534 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "535 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "536 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "537 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "538 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "539 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "540 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "541 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "542 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "543 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "544 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "545 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "546 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "547 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "548 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "549 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "550 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "551 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "552 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "553 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "554 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "555 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "556 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "557 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "558 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "559 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "560 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "561 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "562 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "563 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "564 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "565 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "566 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "567 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "568 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "569 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "570 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "571 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "572 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "573 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "574 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "575 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "576 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "577 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "578 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "579 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "580 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "581 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "582 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "583 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "584 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "585 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "586 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "587 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "588 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "589 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "590 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "591 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "592 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "593 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "594 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "595 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "596 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "597 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "598 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n",
      "599 epoch , train loss : 0.000 \t val_loss : 0.890 \t 0.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 600\n",
    "lr = 0.01\n",
    "wd = 0\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=wd)\n",
    "# t_loss = nn.MSELoss()\n",
    "# v_loss = nn.MSELoss()\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    ## 임베딩레이어는 long -> int 형 자료형으로 넣어야함\n",
    "    users = torch.LongTensor(train.userId.values).to(device)\n",
    "    items = torch.LongTensor(train.movieId.values).to(device)\n",
    "    ratings = torch.FloatTensor(train.rating.values).to(device)\n",
    "    \n",
    "    \n",
    "\n",
    "    y_hat = model(users,items)\n",
    "    y_hat = y_hat.type(torch.FloatTensor).to(device)\n",
    "    t_loss = F.mse_loss(y_hat,ratings)\n",
    "    \n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    t_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    ## 팽가\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        users = torch.LongTensor(val.userId.values).to(device)\n",
    "        items = torch.LongTensor(val.movieId.values).to(device)\n",
    "        ratings = torch.FloatTensor(val.rating.values).to(device)\n",
    "        y_hat = model(users,items)\n",
    "        \n",
    "        \n",
    "        correct = (ratings == y_hat.to(device)).sum().item() \n",
    "        \n",
    "        v_loss = F.mse_loss(y_hat,ratings)\n",
    "    \n",
    "    print(f\"{i} epoch , train loss : {t_loss:.3f} \\t val_loss : {v_loss:.3f} \\t {(correct/len(ratings))*100}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 14,  14,  14,  ..., 513, 513, 513], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,   43,  224,  ..., 7619, 7653, 7803], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 3.5000, 5.0000,  ..., 4.0000, 4.5000, 5.0000], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.4426, 3.2395, 3.9963,  ..., 4.8663, 4.3530, 4.6669], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.4426, 3.2395, 3.9963,  ..., 4.8663, 4.3530, 4.6669], device='cuda:0')\n",
      "tensor([3.5000, 3.0000, 4.0000,  ..., 5.0000, 4.5000, 4.5000],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(y_hat)\n",
    "y_hat_numpy = y_hat.detach().cpu().numpy()\n",
    "# print(np.round(x,1))\n",
    "\n",
    "def refine_rating(x):\n",
    "    rating_list = np.array([0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5])\n",
    "    result = []    \n",
    "    for item in x:\n",
    "        idx = (np.abs(rating_list - item)).argmin()\n",
    "        result.append(rating_list[idx])   \n",
    "    return result\n",
    "\n",
    "refine_y_hat = refine_rating(y_hat_numpy)\n",
    "refine_y_hat = torch.tensor(refine_y_hat)\n",
    "print(refine_y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch , train loss : 0.000 \t val_loss : 0.889 \t 24.26%\n",
      "1 epoch , train loss : 0.000 \t val_loss : 1.097 \t 24.26%\n",
      "2 epoch , train loss : 0.109 \t val_loss : 0.893 \t 24.26%\n",
      "3 epoch , train loss : 0.028 \t val_loss : 0.871 \t 24.26%\n",
      "4 epoch , train loss : 0.073 \t val_loss : 0.881 \t 24.26%\n",
      "5 epoch , train loss : 0.064 \t val_loss : 0.908 \t 24.26%\n",
      "6 epoch , train loss : 0.030 \t val_loss : 0.934 \t 24.26%\n",
      "7 epoch , train loss : 0.021 \t val_loss : 0.949 \t 24.26%\n",
      "8 epoch , train loss : 0.033 \t val_loss : 0.942 \t 24.26%\n",
      "9 epoch , train loss : 0.036 \t val_loss : 0.915 \t 24.26%\n",
      "10 epoch , train loss : 0.025 \t val_loss : 0.891 \t 24.26%\n",
      "11 epoch , train loss : 0.015 \t val_loss : 0.880 \t 24.26%\n",
      "12 epoch , train loss : 0.014 \t val_loss : 0.878 \t 24.26%\n",
      "13 epoch , train loss : 0.019 \t val_loss : 0.878 \t 24.26%\n",
      "14 epoch , train loss : 0.019 \t val_loss : 0.881 \t 24.26%\n",
      "15 epoch , train loss : 0.014 \t val_loss : 0.889 \t 24.26%\n",
      "16 epoch , train loss : 0.009 \t val_loss : 0.899 \t 24.26%\n",
      "17 epoch , train loss : 0.009 \t val_loss : 0.907 \t 24.26%\n",
      "18 epoch , train loss : 0.011 \t val_loss : 0.909 \t 24.26%\n",
      "19 epoch , train loss : 0.011 \t val_loss : 0.905 \t 24.26%\n",
      "20 epoch , train loss : 0.008 \t val_loss : 0.894 \t 24.26%\n",
      "21 epoch , train loss : 0.006 \t val_loss : 0.881 \t 24.26%\n",
      "22 epoch , train loss : 0.006 \t val_loss : 0.872 \t 24.26%\n",
      "23 epoch , train loss : 0.006 \t val_loss : 0.870 \t 24.26%\n",
      "24 epoch , train loss : 0.006 \t val_loss : 0.875 \t 24.26%\n",
      "25 epoch , train loss : 0.005 \t val_loss : 0.885 \t 24.26%\n",
      "26 epoch , train loss : 0.004 \t val_loss : 0.895 \t 24.26%\n",
      "27 epoch , train loss : 0.004 \t val_loss : 0.901 \t 24.26%\n",
      "28 epoch , train loss : 0.004 \t val_loss : 0.900 \t 24.26%\n",
      "29 epoch , train loss : 0.004 \t val_loss : 0.893 \t 24.26%\n",
      "30 epoch , train loss : 0.003 \t val_loss : 0.885 \t 24.26%\n",
      "31 epoch , train loss : 0.002 \t val_loss : 0.878 \t 24.26%\n",
      "32 epoch , train loss : 0.002 \t val_loss : 0.876 \t 24.26%\n",
      "33 epoch , train loss : 0.002 \t val_loss : 0.877 \t 24.26%\n",
      "34 epoch , train loss : 0.002 \t val_loss : 0.881 \t 24.26%\n",
      "35 epoch , train loss : 0.002 \t val_loss : 0.887 \t 24.26%\n",
      "36 epoch , train loss : 0.002 \t val_loss : 0.891 \t 24.26%\n",
      "37 epoch , train loss : 0.002 \t val_loss : 0.892 \t 24.26%\n",
      "38 epoch , train loss : 0.001 \t val_loss : 0.890 \t 24.26%\n",
      "39 epoch , train loss : 0.001 \t val_loss : 0.887 \t 24.26%\n",
      "40 epoch , train loss : 0.001 \t val_loss : 0.884 \t 24.26%\n",
      "41 epoch , train loss : 0.001 \t val_loss : 0.882 \t 24.26%\n",
      "42 epoch , train loss : 0.001 \t val_loss : 0.881 \t 24.26%\n",
      "43 epoch , train loss : 0.001 \t val_loss : 0.881 \t 24.26%\n",
      "44 epoch , train loss : 0.001 \t val_loss : 0.882 \t 24.26%\n",
      "45 epoch , train loss : 0.001 \t val_loss : 0.885 \t 24.26%\n",
      "46 epoch , train loss : 0.001 \t val_loss : 0.888 \t 24.26%\n",
      "47 epoch , train loss : 0.001 \t val_loss : 0.890 \t 24.26%\n",
      "48 epoch , train loss : 0.000 \t val_loss : 0.889 \t 24.26%\n",
      "49 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "50 epoch , train loss : 0.000 \t val_loss : 0.883 \t 24.26%\n",
      "51 epoch , train loss : 0.000 \t val_loss : 0.880 \t 24.26%\n",
      "52 epoch , train loss : 0.000 \t val_loss : 0.880 \t 24.26%\n",
      "53 epoch , train loss : 0.000 \t val_loss : 0.883 \t 24.26%\n",
      "54 epoch , train loss : 0.000 \t val_loss : 0.887 \t 24.26%\n",
      "55 epoch , train loss : 0.000 \t val_loss : 0.889 \t 24.26%\n",
      "56 epoch , train loss : 0.000 \t val_loss : 0.888 \t 24.26%\n",
      "57 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "58 epoch , train loss : 0.000 \t val_loss : 0.883 \t 24.26%\n",
      "59 epoch , train loss : 0.000 \t val_loss : 0.882 \t 24.26%\n",
      "60 epoch , train loss : 0.000 \t val_loss : 0.883 \t 24.26%\n",
      "61 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "62 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "63 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "64 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "65 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "66 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "67 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "68 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "69 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "70 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "71 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "72 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "73 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "74 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "75 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "76 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "77 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "78 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "79 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "80 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "81 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "82 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "83 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "84 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "85 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "86 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "87 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "88 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "89 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "90 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "91 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "92 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "93 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "94 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "95 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "96 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "97 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "98 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "99 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "100 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "101 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "102 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "103 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "104 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "105 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "106 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "107 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "108 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "109 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "110 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "111 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "112 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "113 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "114 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "115 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "116 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "117 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "118 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "119 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "120 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "121 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "122 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "123 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "124 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "125 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "126 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "127 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "128 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "129 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "130 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "131 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "132 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "133 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "134 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "135 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "136 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "137 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "138 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "139 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "140 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "141 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "142 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "143 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "144 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "145 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "146 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "147 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "148 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "149 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "150 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "151 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "152 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "153 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "154 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "155 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "156 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "157 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "158 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "159 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "160 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "161 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "162 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "163 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "164 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "165 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "166 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "167 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "168 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "169 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "170 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "171 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "172 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "173 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "174 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "175 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "176 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "177 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "178 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "179 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "180 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "181 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "182 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "183 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "184 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "185 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "186 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "187 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "188 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "189 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "190 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "191 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "192 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "193 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "194 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "195 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "196 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "197 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "198 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "199 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "200 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "201 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "202 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "203 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "204 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "205 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "206 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "207 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "208 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "209 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "210 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "211 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "212 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "213 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "214 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "215 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "216 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "217 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "218 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "219 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "220 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "221 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "222 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "223 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "224 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "225 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "226 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "227 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "228 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "229 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "230 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "231 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "232 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "233 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "234 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "235 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "236 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "237 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "238 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "239 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "240 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "241 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "242 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "243 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "244 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "245 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "246 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "247 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "248 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "249 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "250 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "251 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "252 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "253 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "254 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "255 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "256 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "257 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "258 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "259 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "260 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "261 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "262 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "263 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "264 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "265 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "266 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "267 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "268 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "269 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "270 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "271 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "272 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "273 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "274 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "275 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "276 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "277 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "278 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "279 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "280 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "281 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "282 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "283 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "284 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "285 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "286 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "287 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "288 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "289 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "290 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "291 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "292 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "293 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "294 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "295 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "296 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "297 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "298 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "299 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "300 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "301 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "302 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "303 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "304 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "305 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "306 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "307 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "308 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "309 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "310 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "311 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "312 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "313 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "314 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "315 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "316 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "317 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "318 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "319 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "320 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "321 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "322 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "323 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "324 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "325 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "326 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "327 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "328 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "329 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "330 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "331 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "332 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "333 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "334 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "335 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "336 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "337 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "338 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "339 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "340 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "341 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "342 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "343 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "344 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "345 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "346 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "347 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "348 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "349 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "350 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "351 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "352 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "353 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "354 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "355 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "356 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "357 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "358 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "359 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "360 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "361 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "362 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "363 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "364 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "365 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "366 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "367 epoch , train loss : 0.001 \t val_loss : 0.884 \t 24.26%\n",
      "368 epoch , train loss : 0.001 \t val_loss : 0.887 \t 24.26%\n",
      "369 epoch , train loss : 0.001 \t val_loss : 0.884 \t 24.26%\n",
      "370 epoch , train loss : 0.001 \t val_loss : 0.887 \t 24.26%\n",
      "371 epoch , train loss : 0.001 \t val_loss : 0.884 \t 24.26%\n",
      "372 epoch , train loss : 0.001 \t val_loss : 0.886 \t 24.26%\n",
      "373 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "374 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "375 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "376 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "377 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "378 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "379 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "380 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "381 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "382 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "383 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "384 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "385 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "386 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "387 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "388 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "389 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "390 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "391 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "392 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "393 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "394 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "395 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "396 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "397 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "398 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "399 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "400 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "401 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "402 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "403 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "404 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "405 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "406 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "407 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "408 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "409 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "410 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "411 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "412 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "413 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "414 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "415 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "416 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "417 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "418 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "419 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "420 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "421 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "422 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "423 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "424 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "425 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "426 epoch , train loss : 0.000 \t val_loss : 0.887 \t 24.26%\n",
      "427 epoch , train loss : 0.001 \t val_loss : 0.883 \t 24.26%\n",
      "428 epoch , train loss : 0.001 \t val_loss : 0.888 \t 24.26%\n",
      "429 epoch , train loss : 0.001 \t val_loss : 0.883 \t 24.26%\n",
      "430 epoch , train loss : 0.002 \t val_loss : 0.889 \t 24.26%\n",
      "431 epoch , train loss : 0.002 \t val_loss : 0.883 \t 24.26%\n",
      "432 epoch , train loss : 0.002 \t val_loss : 0.889 \t 24.26%\n",
      "433 epoch , train loss : 0.002 \t val_loss : 0.883 \t 24.26%\n",
      "434 epoch , train loss : 0.001 \t val_loss : 0.887 \t 24.26%\n",
      "435 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "436 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "437 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "438 epoch , train loss : 0.000 \t val_loss : 0.883 \t 24.26%\n",
      "439 epoch , train loss : 0.001 \t val_loss : 0.887 \t 24.26%\n",
      "440 epoch , train loss : 0.001 \t val_loss : 0.883 \t 24.26%\n",
      "441 epoch , train loss : 0.001 \t val_loss : 0.887 \t 24.26%\n",
      "442 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "443 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "444 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "445 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "446 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "447 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "448 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "449 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "450 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "451 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "452 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "453 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "454 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "455 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "456 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "457 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "458 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "459 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "460 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "461 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "462 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "463 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "464 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "465 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "466 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "467 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "468 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "469 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "470 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "471 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "472 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "473 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "474 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "475 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "476 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "477 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "478 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "479 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "480 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "481 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "482 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "483 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "484 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "485 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "486 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "487 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "488 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "489 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "490 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "491 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "492 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "493 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "494 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "495 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "496 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "497 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "498 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "499 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "500 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "501 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "502 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "503 epoch , train loss : 0.000 \t val_loss : 0.883 \t 24.26%\n",
      "504 epoch , train loss : 0.000 \t val_loss : 0.887 \t 24.26%\n",
      "505 epoch , train loss : 0.001 \t val_loss : 0.883 \t 24.26%\n",
      "506 epoch , train loss : 0.001 \t val_loss : 0.889 \t 24.26%\n",
      "507 epoch , train loss : 0.001 \t val_loss : 0.883 \t 24.26%\n",
      "508 epoch , train loss : 0.002 \t val_loss : 0.890 \t 24.26%\n",
      "509 epoch , train loss : 0.002 \t val_loss : 0.883 \t 24.26%\n",
      "510 epoch , train loss : 0.002 \t val_loss : 0.890 \t 24.26%\n",
      "511 epoch , train loss : 0.002 \t val_loss : 0.883 \t 24.26%\n",
      "512 epoch , train loss : 0.002 \t val_loss : 0.889 \t 24.26%\n",
      "513 epoch , train loss : 0.001 \t val_loss : 0.883 \t 24.26%\n",
      "514 epoch , train loss : 0.001 \t val_loss : 0.886 \t 24.26%\n",
      "515 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "516 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "517 epoch , train loss : 0.000 \t val_loss : 0.887 \t 24.26%\n",
      "518 epoch , train loss : 0.001 \t val_loss : 0.883 \t 24.26%\n",
      "519 epoch , train loss : 0.001 \t val_loss : 0.888 \t 24.26%\n",
      "520 epoch , train loss : 0.001 \t val_loss : 0.883 \t 24.26%\n",
      "521 epoch , train loss : 0.001 \t val_loss : 0.887 \t 24.26%\n",
      "522 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "523 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "524 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "525 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "526 epoch , train loss : 0.000 \t val_loss : 0.887 \t 24.26%\n",
      "527 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "528 epoch , train loss : 0.000 \t val_loss : 0.887 \t 24.26%\n",
      "529 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "530 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "531 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "532 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "533 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "534 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "535 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "536 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "537 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "538 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "539 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "540 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "541 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "542 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "543 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "544 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "545 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "546 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "547 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "548 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "549 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "550 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "551 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "552 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "553 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "554 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "555 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "556 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "557 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "558 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "559 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "560 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "561 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "562 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "563 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "564 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "565 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "566 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "567 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "568 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "569 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "570 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "571 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "572 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "573 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "574 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "575 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "576 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "577 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "578 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "579 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "580 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "581 epoch , train loss : 0.000 \t val_loss : 0.887 \t 24.26%\n",
      "582 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "583 epoch , train loss : 0.001 \t val_loss : 0.888 \t 24.26%\n",
      "584 epoch , train loss : 0.001 \t val_loss : 0.883 \t 24.26%\n",
      "585 epoch , train loss : 0.001 \t val_loss : 0.890 \t 24.26%\n",
      "586 epoch , train loss : 0.002 \t val_loss : 0.883 \t 24.26%\n",
      "587 epoch , train loss : 0.002 \t val_loss : 0.892 \t 24.26%\n",
      "588 epoch , train loss : 0.003 \t val_loss : 0.883 \t 24.26%\n",
      "589 epoch , train loss : 0.003 \t val_loss : 0.892 \t 24.26%\n",
      "590 epoch , train loss : 0.003 \t val_loss : 0.883 \t 24.26%\n",
      "591 epoch , train loss : 0.002 \t val_loss : 0.889 \t 24.26%\n",
      "592 epoch , train loss : 0.001 \t val_loss : 0.884 \t 24.26%\n",
      "593 epoch , train loss : 0.000 \t val_loss : 0.885 \t 24.26%\n",
      "594 epoch , train loss : 0.000 \t val_loss : 0.886 \t 24.26%\n",
      "595 epoch , train loss : 0.000 \t val_loss : 0.884 \t 24.26%\n",
      "596 epoch , train loss : 0.001 \t val_loss : 0.889 \t 24.26%\n",
      "597 epoch , train loss : 0.001 \t val_loss : 0.884 \t 24.26%\n",
      "598 epoch , train loss : 0.001 \t val_loss : 0.889 \t 24.26%\n",
      "599 epoch , train loss : 0.001 \t val_loss : 0.884 \t 24.26%\n"
     ]
    }
   ],
   "source": [
    "epochs = 600\n",
    "lr = 0.01\n",
    "wd = 0\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=wd)\n",
    "# t_loss = nn.MSELoss()\n",
    "# v_loss = nn.MSELoss()\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    ## 임베딩레이어는 long -> int 형 자료형으로 넣어야함\n",
    "    users = torch.LongTensor(train.userId.values).to(device)\n",
    "    items = torch.LongTensor(train.movieId.values).to(device)\n",
    "    ratings = torch.FloatTensor(train.rating.values).to(device)\n",
    "    \n",
    "    \n",
    "\n",
    "    y_hat = model(users,items)\n",
    "    y_hat = y_hat.type(torch.FloatTensor).to(device)\n",
    "    t_loss = F.mse_loss(y_hat,ratings)\n",
    "    \n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    t_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    ## 팽가\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        users = torch.LongTensor(val.userId.values).to(device)\n",
    "        items = torch.LongTensor(val.movieId.values).to(device)\n",
    "        ratings = torch.FloatTensor(val.rating.values).to(device)\n",
    "        y_hat = model(users,items)\n",
    "        \n",
    "        refine_y_hat = refine_rating(y_hat_numpy)\n",
    "        refine_y_hat = torch.tensor(refine_y_hat)\n",
    "        \n",
    "        correct = (ratings == refine_y_hat.to(device)).sum().item() \n",
    "        \n",
    "        v_loss = F.mse_loss(y_hat,ratings)\n",
    "    \n",
    "    print(f\"{i} epoch , train loss : {t_loss:.3f} \\t val_loss : {v_loss:.3f} \\t {(correct/len(ratings))*100:.2f}%\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311\n",
      "318\n"
     ]
    }
   ],
   "source": [
    "y1 = ratings.detach().cpu().tolist()\n",
    "y2 = refine_y_hat.detach().cpu().tolist()\n",
    "\n",
    "print(len(refine_y_hat))\n",
    "\n",
    "count=0\n",
    "for i in range(0,len(y1)):\n",
    "    if y1[i] == y2[i]:\n",
    "        count+=1\n",
    "        # print(f\"{i}번째 맞음\")\n",
    "        \n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80a488a2e0e5e7c759746e5071f8ef13c7ede312d2049d49ac9bba0fb75c351b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
