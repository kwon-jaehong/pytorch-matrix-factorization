{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/save/NCF/ml-1m.test.negative'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21738/2527969940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m############################## PREPARE DATASET ##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21738/2527969940.py\u001b[0m in \u001b[0;36mload_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_negative\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/save/NCF/ml-1m.test.negative'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "################################## config.py ###########################\n",
    "config = {\n",
    "    \"model\": \"MF\",\n",
    "    \"model_path\": \"./models/\",\n",
    "    \"train_rating\": \"./data/ml-1m.train.rating\",\n",
    "    \"train_negative\": \"./data/ml-1m.train.negative\",\n",
    "    \"test_negative\": \"./data/ml-1m.test.negative\",\n",
    "}\n",
    "\n",
    "args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"dropout\": 0.0,\n",
    "    \"epochs\": 20,\n",
    "    \"factor_num\": 32,\n",
    "    \"gpu\": \"0\",\n",
    "    \"lr\": 0.001,\n",
    "    \"num_layers\": 3,\n",
    "    \"num_ng\": 4,\n",
    "    \"out\": True,\n",
    "    \"test_num_ng\": 99,\n",
    "    \"top_k\": 10,\n",
    "}\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args[\"gpu\"]\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "########################## data_utils.py ####################\n",
    "def load_all():\n",
    "    \"\"\" We load all the three file here to save time in each epoch. \"\"\"\n",
    "    train_data = pd.read_csv(\n",
    "        config[\"train_rating\"],\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"user\", \"item\"],\n",
    "        usecols=[0, 1],\n",
    "        dtype={0: np.int32, 1: np.int32},\n",
    "    )\n",
    "\n",
    "    user_num = train_data[\"user\"].max() + 1\n",
    "    item_num = train_data[\"item\"].max() + 1\n",
    "\n",
    "    train_data = train_data.values.tolist()\n",
    "\n",
    "    # dok matrix 형식으로 저장\n",
    "    train_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
    "    for x in train_data:\n",
    "        train_mat[x[0], x[1]] = 1.0\n",
    "\n",
    "    test_data = []\n",
    "    with open(config[\"test_negative\"], \"r\") as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(\"\\t\")\n",
    "            u = eval(arr[0])[0]\n",
    "            test_data.append([u, eval(arr[0])[1]])\n",
    "            for i in arr[1:]:\n",
    "                test_data.append([u, int(i)])\n",
    "            line = fd.readline()\n",
    "    return train_data, test_data, user_num, item_num, train_mat\n",
    "\n",
    "\n",
    "class NCFData(data.Dataset):\n",
    "    def __init__(self, features, num_item, train_mat=None, num_ng=0, is_training=None):\n",
    "        super(NCFData, self).__init__()\n",
    "        \"\"\" Note that the labels are only useful when training, we thus \n",
    "\t\t\tadd them in the ng_sample() function.\n",
    "\t\t\"\"\"\n",
    "        self.features_ps = features\n",
    "        self.num_item = num_item\n",
    "        self.train_mat = train_mat\n",
    "        self.num_ng = num_ng\n",
    "        self.is_training = is_training\n",
    "        self.labels = [0] * len(features)\n",
    "\n",
    "    def set_ng_sample(self):\n",
    "        assert self.is_training, \"no need to sampling when testing\"\n",
    "\n",
    "        # negative sample 더하기\n",
    "        self.features_ng = []\n",
    "        for x in self.features_ps:\n",
    "            # user\n",
    "            u = x[0]\n",
    "            for _ in range(self.num_ng):\n",
    "                j = np.random.randint(self.num_item)\n",
    "                # train set에 있는 경우 다시 뽑기\n",
    "                while (u, j) in self.train_mat:\n",
    "                    j = np.random.randint(self.num_item)\n",
    "                self.features_ng.append([u, j])\n",
    "\n",
    "        labels_ps = [1] * len(self.features_ps)\n",
    "        labels_ng = [0] * len(self.features_ng)\n",
    "\n",
    "        self.features_fill = self.features_ps + self.features_ng\n",
    "        self.labels_fill = labels_ps + labels_ng\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_ng + 1) * len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features_fill if self.is_training else self.features_ps\n",
    "        labels = self.labels_fill if self.is_training else self.labels\n",
    "\n",
    "        user = features[idx][0]\n",
    "        item = features[idx][1]\n",
    "        label = labels[idx]\n",
    "        return user, item, label\n",
    "\n",
    "\n",
    "############################## PREPARE DATASET ##########################\n",
    "train_data, test_data, user_num, item_num, train_mat = load_all()\n",
    "\n",
    "\n",
    "def prepare_data(train_data, test_data, item_num, train_mat):\n",
    "\n",
    "    # construct the train and test datasets\n",
    "    # args = (features, num_item, train_mat=None, num_ng=0, is_training=None)\n",
    "    train_dataset = NCFData(train_data, item_num, train_mat, args[\"num_ng\"], True)\n",
    "    test_dataset = NCFData(test_data, item_num, train_mat, 0, False)\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dataset, batch_size=args[\"batch_size\"], shuffle=True, num_workers=4\n",
    "    )\n",
    "    test_loader = data.DataLoader(\n",
    "        test_dataset, batch_size=args[\"test_num_ng\"] + 1, shuffle=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "train_loader, test_loader = prepare_data(train_data, test_data, item_num, train_mat)\n",
    "\n",
    "\n",
    "############################## model.py ###############################\n",
    "\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(\n",
    "        self, user_num, item_num, factor_num,\n",
    "    ):\n",
    "        super(MF, self).__init__()\n",
    "        self.factor_num = factor_num\n",
    "\n",
    "        # 임베딩 저장공간 확보; num_embeddings, embedding_dim\n",
    "        self.embed_user = nn.Embedding(user_num, factor_num)\n",
    "        self.embed_item = nn.Embedding(item_num, factor_num)\n",
    "        predict_size = factor_num\n",
    "        self.predict_layer = torch.ones(predict_size, 1).cuda()\n",
    "        self._init_weight_()\n",
    "\n",
    "    def _init_weight_(self):\n",
    "        # weight 초기화\n",
    "        nn.init.normal_(self.embed_user.weight, std=0.01)\n",
    "        nn.init.normal_(self.embed_item.weight, std=0.01)\n",
    "\n",
    "        # bias 초기화\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        embed_user = self.embed_user(user)\n",
    "        embed_item = self.embed_item(item)\n",
    "        output_GMF = embed_user * embed_item\n",
    "        prediction = torch.matmul(output_GMF, self.predict_layer)\n",
    "        return prediction.view(-1)\n",
    "\n",
    "\n",
    "########################### CREATE MODEL #################################\n",
    "\n",
    "\n",
    "def create_model(user_num, item_num, args):\n",
    "    model = MF(user_num, item_num, args[\"factor_num\"],)\n",
    "    model.cuda()\n",
    "    loss_function = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
    "    return model, loss_function, optimizer\n",
    "\n",
    "\n",
    "model, loss_function, optimizer = create_model(user_num, item_num, args)\n",
    "\n",
    "\n",
    "############################ evaluate.py ###############################\n",
    "\n",
    "\n",
    "def hit(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def ndcg(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        index = pred_items.index(gt_item)\n",
    "        return np.reciprocal(np.log2(index + 2))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def metrics(model, test_loader, top_k):\n",
    "    HR, NDCG = [], []\n",
    "\n",
    "    for user, item, _ in test_loader:\n",
    "        user = user.cuda()\n",
    "        item = item.cuda()\n",
    "\n",
    "        predictions = model(user, item)\n",
    "        # 가장 높은 top_k개 선택\n",
    "        _, indices = torch.topk(predictions, top_k)\n",
    "        # 해당 상품 index 선택\n",
    "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "        # 정답값 선택\n",
    "        gt_item = item[0].item()\n",
    "        HR.append(hit(gt_item, recommends))\n",
    "        NDCG.append(ndcg(gt_item, recommends))\n",
    "\n",
    "    return np.mean(HR), np.mean(NDCG)\n",
    "\n",
    "\n",
    "########################### TRAINING #####################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count, best_hr = 0, 0\n",
    "    writer = SummaryWriter()  # for visualization\n",
    "    # 모델 파라미터 출력\n",
    "    for epoch in range(args[\"epochs\"]):\n",
    "        model.train()  # Enable dropout (if have).\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_loader.dataset.set_ng_sample()\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.cuda()\n",
    "            item = item.cuda()\n",
    "            label = label.float().cuda()\n",
    "\n",
    "            # gradient 초기화\n",
    "            model.zero_grad()\n",
    "            prediction = model(user, item)\n",
    "            loss = loss_function(prediction, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar(\"data/loss\", loss.item(), count)\n",
    "            count += 1\n",
    "\n",
    "        model.eval()\n",
    "        HR, NDCG = metrics(model, test_loader, args[\"top_k\"])\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\n",
    "            \"The time elapse of epoch {:03d}\".format(epoch)\n",
    "            + \" is: \"\n",
    "            + time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time))\n",
    "        )\n",
    "        print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
    "\n",
    "        if HR > best_hr:\n",
    "            best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
    "            if args[\"out\"]:\n",
    "                if not os.path.exists(config[\"model_path\"]):\n",
    "                    os.mkdir(config[\"model_path\"])\n",
    "                torch.save(\n",
    "                    model, \"{}{}.pth\".format(config[\"model_path\"], config[\"model\"])\n",
    "                )\n",
    "\n",
    "    print(\n",
    "        \"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(\n",
    "            best_epoch, best_hr, best_ndcg\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80a488a2e0e5e7c759746e5071f8ef13c7ede312d2049d49ac9bba0fb75c351b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
