{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time elapse of epoch 000 is: 00: 00: 48\n",
      "HR: 0.523\tNDCG: 0.293\n",
      "The time elapse of epoch 001 is: 00: 00: 47\n",
      "HR: 0.599\tNDCG: 0.340\n",
      "The time elapse of epoch 002 is: 00: 00: 48\n",
      "HR: 0.644\tNDCG: 0.374\n",
      "The time elapse of epoch 003 is: 00: 00: 46\n",
      "HR: 0.664\tNDCG: 0.391\n",
      "The time elapse of epoch 004 is: 00: 00: 47\n",
      "HR: 0.682\tNDCG: 0.403\n",
      "The time elapse of epoch 005 is: 00: 00: 47\n",
      "HR: 0.691\tNDCG: 0.411\n",
      "The time elapse of epoch 006 is: 00: 00: 48\n",
      "HR: 0.701\tNDCG: 0.415\n",
      "The time elapse of epoch 007 is: 00: 00: 47\n",
      "HR: 0.695\tNDCG: 0.419\n",
      "The time elapse of epoch 008 is: 00: 00: 48\n",
      "HR: 0.696\tNDCG: 0.419\n",
      "The time elapse of epoch 009 is: 00: 00: 48\n",
      "HR: 0.697\tNDCG: 0.422\n",
      "The time elapse of epoch 010 is: 00: 00: 49\n",
      "HR: 0.700\tNDCG: 0.422\n",
      "The time elapse of epoch 011 is: 00: 00: 48\n",
      "HR: 0.699\tNDCG: 0.421\n",
      "The time elapse of epoch 012 is: 00: 00: 48\n",
      "HR: 0.701\tNDCG: 0.422\n",
      "The time elapse of epoch 013 is: 00: 00: 47\n",
      "HR: 0.702\tNDCG: 0.423\n",
      "The time elapse of epoch 014 is: 00: 00: 46\n",
      "HR: 0.703\tNDCG: 0.421\n",
      "The time elapse of epoch 015 is: 00: 00: 47\n",
      "HR: 0.694\tNDCG: 0.418\n",
      "The time elapse of epoch 016 is: 00: 00: 46\n",
      "HR: 0.694\tNDCG: 0.418\n",
      "The time elapse of epoch 017 is: 00: 00: 47\n",
      "HR: 0.696\tNDCG: 0.418\n",
      "The time elapse of epoch 018 is: 00: 00: 47\n",
      "HR: 0.696\tNDCG: 0.421\n",
      "The time elapse of epoch 019 is: 00: 00: 46\n",
      "HR: 0.698\tNDCG: 0.419\n",
      "End. Best epoch 014: HR = 0.703, NDCG = 0.421\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "################################## config.py ###########################\n",
    "config = {\n",
    "    \"model\": \"MF\",\n",
    "    \"model_path\": \"./models/\",\n",
    "    \"train_rating\": \"./data/ml-1m.train.rating\",\n",
    "    \"train_negative\": \"./data/ml-1m.train.negative\",\n",
    "    \"test_negative\": \"./data/ml-1m.test.negative\",\n",
    "}\n",
    "\n",
    "args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"dropout\": 0.0,\n",
    "    \"epochs\": 20,\n",
    "    \"factor_num\": 32,\n",
    "    \"gpu\": \"0\",\n",
    "    \"lr\": 0.001,\n",
    "    \"num_layers\": 3,\n",
    "    \"num_ng\": 4,\n",
    "    \"out\": True,\n",
    "    \"test_num_ng\": 99,\n",
    "    \"top_k\": 10,\n",
    "}\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args[\"gpu\"]\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "########################## data_utils.py ####################\n",
    "def load_all():\n",
    "    \"\"\" We load all the three file here to save time in each epoch. \"\"\"\n",
    "    train_data = pd.read_csv(\n",
    "        config[\"train_rating\"],\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"user\", \"item\"],\n",
    "        usecols=[0, 1],\n",
    "        dtype={0: np.int32, 1: np.int32},\n",
    "    )\n",
    "\n",
    "    user_num = train_data[\"user\"].max() + 1\n",
    "    item_num = train_data[\"item\"].max() + 1\n",
    "\n",
    "    train_data = train_data.values.tolist()\n",
    "\n",
    "    # dok matrix 형식으로 저장\n",
    "    train_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
    "    for x in train_data:\n",
    "        train_mat[x[0], x[1]] = 1.0\n",
    "\n",
    "    test_data = []\n",
    "    with open(config[\"test_negative\"], \"r\") as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(\"\\t\")\n",
    "            u = eval(arr[0])[0]\n",
    "            test_data.append([u, eval(arr[0])[1]])\n",
    "            for i in arr[1:]:\n",
    "                test_data.append([u, int(i)])\n",
    "            line = fd.readline()\n",
    "    return train_data, test_data, user_num, item_num, train_mat\n",
    "\n",
    "\n",
    "class NCFData(data.Dataset):\n",
    "    def __init__(self, features, num_item, train_mat=None, num_ng=0, is_training=None):\n",
    "        super(NCFData, self).__init__()\n",
    "        \"\"\" Note that the labels are only useful when training, we thus \n",
    "\t\t\tadd them in the ng_sample() function.\n",
    "\t\t\"\"\"\n",
    "        self.features_ps = features\n",
    "        self.num_item = num_item\n",
    "        self.train_mat = train_mat\n",
    "        self.num_ng = num_ng\n",
    "        self.is_training = is_training\n",
    "        self.labels = [0] * len(features)\n",
    "\n",
    "    def set_ng_sample(self):\n",
    "        assert self.is_training, \"no need to sampling when testing\"\n",
    "\n",
    "        # negative sample 더하기\n",
    "        self.features_ng = []\n",
    "        for x in self.features_ps:\n",
    "            # user\n",
    "            u = x[0]\n",
    "            for _ in range(self.num_ng):\n",
    "                j = np.random.randint(self.num_item)\n",
    "                # train set에 있는 경우 다시 뽑기\n",
    "                while (u, j) in self.train_mat:\n",
    "                    j = np.random.randint(self.num_item)\n",
    "                self.features_ng.append([u, j])\n",
    "\n",
    "        labels_ps = [1] * len(self.features_ps)\n",
    "        labels_ng = [0] * len(self.features_ng)\n",
    "\n",
    "        self.features_fill = self.features_ps + self.features_ng\n",
    "        self.labels_fill = labels_ps + labels_ng\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_ng + 1) * len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features_fill if self.is_training else self.features_ps\n",
    "        labels = self.labels_fill if self.is_training else self.labels\n",
    "\n",
    "        user = features[idx][0]\n",
    "        item = features[idx][1]\n",
    "        label = labels[idx]\n",
    "        return user, item, label\n",
    "\n",
    "\n",
    "############################## PREPARE DATASET ##########################\n",
    "train_data, test_data, user_num, item_num, train_mat = load_all()\n",
    "\n",
    "\n",
    "def prepare_data(train_data, test_data, item_num, train_mat):\n",
    "\n",
    "    # construct the train and test datasets\n",
    "    # args = (features, num_item, train_mat=None, num_ng=0, is_training=None)\n",
    "    train_dataset = NCFData(train_data, item_num, train_mat, args[\"num_ng\"], True)\n",
    "    test_dataset = NCFData(test_data, item_num, train_mat, 0, False)\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dataset, batch_size=args[\"batch_size\"], shuffle=True, num_workers=4\n",
    "    )\n",
    "    test_loader = data.DataLoader(\n",
    "        test_dataset, batch_size=args[\"test_num_ng\"] + 1, shuffle=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "train_loader, test_loader = prepare_data(train_data, test_data, item_num, train_mat)\n",
    "\n",
    "\n",
    "############################## model.py ###############################\n",
    "\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(\n",
    "        self, user_num, item_num, factor_num,\n",
    "    ):\n",
    "        super(MF, self).__init__()\n",
    "        self.factor_num = factor_num\n",
    "\n",
    "        # 임베딩 저장공간 확보; num_embeddings, embedding_dim\n",
    "        self.embed_user = nn.Embedding(user_num, factor_num)\n",
    "        self.embed_item = nn.Embedding(item_num, factor_num)\n",
    "        predict_size = factor_num\n",
    "        self.predict_layer = torch.ones(predict_size, 1).cuda()\n",
    "        self._init_weight_()\n",
    "\n",
    "    def _init_weight_(self):\n",
    "        # weight 초기화\n",
    "        nn.init.normal_(self.embed_user.weight, std=0.01)\n",
    "        nn.init.normal_(self.embed_item.weight, std=0.01)\n",
    "\n",
    "        # bias 초기화\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        embed_user = self.embed_user(user)\n",
    "        embed_item = self.embed_item(item)\n",
    "        output_GMF = embed_user * embed_item\n",
    "        prediction = torch.matmul(output_GMF, self.predict_layer)\n",
    "        return prediction.view(-1)\n",
    "\n",
    "\n",
    "########################### CREATE MODEL #################################\n",
    "\n",
    "\n",
    "def create_model(user_num, item_num, args):\n",
    "    model = MF(user_num, item_num, args[\"factor_num\"],)\n",
    "    model.cuda()\n",
    "    loss_function = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
    "    return model, loss_function, optimizer\n",
    "\n",
    "\n",
    "model, loss_function, optimizer = create_model(user_num, item_num, args)\n",
    "\n",
    "\n",
    "############################ evaluate.py ###############################\n",
    "\n",
    "\n",
    "def hit(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def ndcg(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        index = pred_items.index(gt_item)\n",
    "        return np.reciprocal(np.log2(index + 2))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def metrics(model, test_loader, top_k):\n",
    "    HR, NDCG = [], []\n",
    "\n",
    "    for user, item, _ in test_loader:\n",
    "        user = user.cuda()\n",
    "        item = item.cuda()\n",
    "\n",
    "        predictions = model(user, item)\n",
    "        # 가장 높은 top_k개 선택\n",
    "        _, indices = torch.topk(predictions, top_k)\n",
    "        # 해당 상품 index 선택\n",
    "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "        # 정답값 선택\n",
    "        gt_item = item[0].item()\n",
    "        HR.append(hit(gt_item, recommends))\n",
    "        NDCG.append(ndcg(gt_item, recommends))\n",
    "\n",
    "    return np.mean(HR), np.mean(NDCG)\n",
    "\n",
    "\n",
    "########################### TRAINING #####################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count, best_hr = 0, 0\n",
    "    writer = SummaryWriter()  # for visualization\n",
    "    # 모델 파라미터 출력\n",
    "    for epoch in range(args[\"epochs\"]):\n",
    "        model.train()  # Enable dropout (if have).\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_loader.dataset.set_ng_sample()\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.cuda()\n",
    "            item = item.cuda()\n",
    "            label = label.float().cuda()\n",
    "\n",
    "            # gradient 초기화\n",
    "            model.zero_grad()\n",
    "            prediction = model(user, item)\n",
    "            loss = loss_function(prediction, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar(\"data/loss\", loss.item(), count)\n",
    "            count += 1\n",
    "\n",
    "        model.eval()\n",
    "        HR, NDCG = metrics(model, test_loader, args[\"top_k\"])\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\n",
    "            \"The time elapse of epoch {:03d}\".format(epoch)\n",
    "            + \" is: \"\n",
    "            + time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time))\n",
    "        )\n",
    "        print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
    "\n",
    "        if HR > best_hr:\n",
    "            best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
    "            if args[\"out\"]:\n",
    "                if not os.path.exists(config[\"model_path\"]):\n",
    "                    os.mkdir(config[\"model_path\"])\n",
    "                torch.save(\n",
    "                    model, \"{}{}.pth\".format(config[\"model_path\"], config[\"model\"])\n",
    "                )\n",
    "\n",
    "    print(\n",
    "        \"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(\n",
    "            best_epoch, best_hr, best_ndcg\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 234, 4516,  668, 1332, 3630, 3402, 5791, 1447, 4084, 4174,  441,   34,\n",
       "        1391, 4639, 4802, 2795, 3888, 3507, 2097, 4699, 4867, 5993, 2353, 4566,\n",
       "        1779, 3952, 1050,   52, 4608, 3647, 6029,  658, 1373, 3468,  695, 3149,\n",
       "        2798, 2453,    8, 2755, 3502, 1448, 4509, 3390,  691, 5625, 2886, 3204,\n",
       "         201, 3962, 5025, 4185,  659, 1925, 4707, 4063, 2452, 3981,  947, 3772,\n",
       "        2333,  923, 4519, 2943, 3241,  328, 3840, 1618, 5719, 5779, 4314, 3545,\n",
       "        5366, 2078, 3823, 4443, 4424, 5697, 1740,  328, 1686, 1864, 2699, 3264,\n",
       "        3891, 2722, 4115, 1151,  452, 4020, 1424, 1878, 2805], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2474,  877,  833, 2685,   48, 3548,  246, 2462, 2990, 2586,  205, 1450,\n",
       "         693, 1945, 2166,  534, 1090, 1652, 2606, 1480, 1717,  949, 1245, 3162,\n",
       "        1583, 2384, 1147, 1067, 2020, 1863, 1000, 3579, 3357, 2896, 2731, 2959,\n",
       "         464, 1663,  111, 2007, 3262,  149, 2601, 2272, 2693,  647, 3443, 1311,\n",
       "        2860, 2082, 2650, 1926, 1023, 1840,  430, 3600,  107,   27, 1864,  622,\n",
       "        1797, 1650, 1927, 2864, 1461, 1159,  806,  257,  139,  437,   46, 1804,\n",
       "        3698, 3333,  949,  512, 2182, 1805,  241,  182, 2599,  955,  297,  659,\n",
       "        1565, 2309, 2291, 3258, 2540, 3339, 2411, 2871,  517], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80a488a2e0e5e7c759746e5071f8ef13c7ede312d2049d49ac9bba0fb75c351b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
